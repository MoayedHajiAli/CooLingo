{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/users/mali18/CooLingo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "while not os.getcwd().endswith('CooLingo'):\n",
    "    os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.liveportrait import LiveSpeechPortraits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt: Namespace(A2L_GMM_ndim=75, APC_frame_history=0, APC_hidden_size=512, APC_residual=False, APC_rnn_layers=3, FPS=60, LSTM_dropout=0, LSTM_hidden_size=256, LSTM_layers=3, LSTM_output_size=80, LSTM_residual=False, LSTM_sequence_length=60, audioRF_future=0, audioRF_history=60, audio_encoder='APC', batch_size=32, checkpoints_dir='./checkpoints/', dataroot='default_path', dataset_mode='audiovisual', dataset_names='default_name', eval=False, feature_decoder='LSTM', feature_dtype='pts3d', frame_future=18, frame_jump_stride=4, gpu_ids='0', ispts_norm=1, load_epoch='500', loss='L2', max_dataset_size=inf, model='audio2feature', name='Audio2Feature', num_threads=0, only_mouth=1, phase='test', predict_length=1, sample_rate=16000, sequence_length=240, serial_batches=False, suffix='', task='Audio2Feature', time_frame_length=1, use_delta_pts=1, verbose=False)\n",
      "----------------- Options ---------------\n",
      "             A2L_GMM_ndim: 75                            \n",
      "        APC_frame_history: 0                             \n",
      "          APC_hidden_size: 512                           \n",
      "             APC_residual: False                         \n",
      "           APC_rnn_layers: 3                             \n",
      "                      FPS: 60                            \n",
      "             LSTM_dropout: 0                             \n",
      "         LSTM_hidden_size: 256                           \n",
      "              LSTM_layers: 3                             \n",
      "         LSTM_output_size: 80                            \n",
      "            LSTM_residual: False                         \n",
      "     LSTM_sequence_length: 60                            \n",
      "           audioRF_future: 0                             \n",
      "          audioRF_history: 60                            \n",
      "            audio_encoder: APC                           \n",
      "               batch_size: 32                            \n",
      "          checkpoints_dir: ./checkpoints/                \n",
      "                 dataroot: default_path                  \n",
      "             dataset_mode: audiovisual                   \n",
      "            dataset_names: default_name                  \n",
      "                     eval: False                         \n",
      "          feature_decoder: LSTM                          \n",
      "            feature_dtype: pts3d                         \n",
      "             frame_future: 18                            \n",
      "        frame_jump_stride: 4                             \n",
      "                  gpu_ids: 0                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "               ispts_norm: 1                             \n",
      "               load_epoch: 500                           \n",
      "                     loss: L2                            \n",
      "         max_dataset_size: inf                           \n",
      "                    model: audio2feature                 \n",
      "                     name: Audio2Feature                 \n",
      "              num_threads: 0                             \n",
      "               only_mouth: 1                             \n",
      "                    phase: test                          \n",
      "           predict_length: 1                             \n",
      "              sample_rate: 16000                         \n",
      "          sequence_length: 240                           \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                     task: Audio2Feature                 \n",
      "        time_frame_length: 1                             \n",
      "            use_delta_pts: 1                             \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "----------------- Options ---------------\n",
      "          A2H_GMM_ncenter: 1                             \n",
      "             A2H_GMM_ndim: 12                            \n",
      "        A2H_GMM_sigma_min: 0.03                          \n",
      "         A2H_wavenet_cond: True                          \n",
      "A2H_wavenet_cond_channels: 512                           \n",
      "A2H_wavenet_dilation_channels: 128                           \n",
      "A2H_wavenet_input_channels: 12                            \n",
      "  A2H_wavenet_kernel_size: 2                             \n",
      "A2H_wavenet_residual_blocks: 2                             \n",
      "A2H_wavenet_residual_channels: 128                           \n",
      "A2H_wavenet_residual_layers: 7                             \n",
      "A2H_wavenet_skip_channels: 256                           \n",
      "     A2H_wavenet_use_bias: True                          \n",
      "        APC_frame_history: 60                            \n",
      "          APC_hidden_size: 512                           \n",
      "             APC_residual: False                         \n",
      "           APC_rnn_layers: 3                             \n",
      "                      FPS: 60                            \n",
      "           audioRF_future: 0                             \n",
      "          audioRF_history: 60                            \n",
      "            audio_encoder: APC                           \n",
      "            audio_windows: 2                             \n",
      "audiofeature_input_channels: 80                            \n",
      "               batch_size: 32                            \n",
      "          checkpoints_dir: ./checkpoints/                \n",
      "                 dataroot: path                          \n",
      "             dataset_mode: audiovisual                   \n",
      "            dataset_names: name                          \n",
      "                     eval: False                         \n",
      "          feature_decoder: WaveNet                       \n",
      "             frame_future: 15                            \n",
      "        frame_jump_stride: 1                             \n",
      "                  gpu_ids: 0                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "               load_epoch: 500                           \n",
      "                     loss: GMM                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: audio2headpose                \n",
      "                     name: Audio2Headpose                \n",
      "              num_threads: 0                             \n",
      "                    phase: test                          \n",
      "           predict_length: 5                             \n",
      "              sample_rate: 16000                         \n",
      "          sequence_length: 240                           \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                     task: Audio2Headpose                \n",
      "        time_frame_length: 1                             \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "------------ Options -------------\n",
      "batch_size: 1\n",
      "checkpoints_dir: ./checkpoints/\n",
      "dataroot: ./data/\n",
      "dataset_mode: face\n",
      "dataset_names: ['name']\n",
      "debug: False\n",
      "display_id: 0\n",
      "display_winsize: 512\n",
      "fineSize: 512\n",
      "fp16: 0\n",
      "gpu_ids: [0]\n",
      "input_nc: 1\n",
      "isH5: 1\n",
      "isMask: 0\n",
      "isTrain: False\n",
      "loadSize: 512\n",
      "load_pretrain: \n",
      "local_rank: 0\n",
      "max_dataset_size: inf\n",
      "model: feature2face\n",
      "n_blocks_E: 3\n",
      "n_downsample_E: 3\n",
      "n_downsample_G: 8\n",
      "name: TestRender\n",
      "ngf: 64\n",
      "ngf_E: 16\n",
      "no_flip: 1\n",
      "num_threads: 0\n",
      "output_nc: 3\n",
      "phase: test\n",
      "resize_or_crop: scaleWidth\n",
      "serial_batches: False\n",
      "suffix: .jpg\n",
      "task: Feature2Face\n",
      "test_dataset_names: ['name']\n",
      "tf_log: True\n",
      "verbose: False\n",
      "-------------- End ----------------\n",
      "large\n",
      "---------- Loading Model: APC-------------\n",
      "pretrained_models/LiveSpeechPortraits/data/APC_epoch_160.model\n",
      "cuda\n",
      "---------- Loading Model: Audio2Feature -------------\n",
      "initialize network with normal\n",
      "model [Audio2FeatureModel] was created\n",
      "loading the model from pretrained_models/LiveSpeechPortraits/data/May/checkpoints/Audio2Feature.pkl\n",
      "---------- Networks initialized -------------\n",
      "[Network Audio2Feature] Total number of parameters : 3.064 M\n",
      "-----------------------------------------------\n",
      "---------- Loading Model: Audio2Headpose -------------\n",
      "initialize network with normal\n",
      "model [Audio2HeadposeModel] was created\n",
      "loading the model from pretrained_models/LiveSpeechPortraits/data/May/checkpoints/Audio2Headpose.pkl\n",
      "---------- Networks initialized -------------\n",
      "[Network Audio2Headpose] Total number of parameters : 4.267 M\n",
      "-----------------------------------------------\n",
      "---------- Loading Model: Feature2Face -------------\n",
      "dataset [FaceDataset] was created\n",
      "Namespace(batch_size=1, checkpoints_dir='./checkpoints/', dataroot='pretrained_models/LiveSpeechPortraits/data/May/', dataset_mode='face', dataset_names=['name'], debug=False, display_id=0, display_winsize=512, fineSize=512, fp16=0, gpu_ids=[0], input_nc=1, isH5=1, isMask=0, isTrain=False, loadSize=512, load_epoch='pretrained_models/LiveSpeechPortraits/data/May/checkpoints/Feature2Face.pkl', load_pretrain='', local_rank=0, max_dataset_size=inf, model='feature2face', n_blocks_E=3, n_downsample_E=3, n_downsample_G=8, name='TestRender', ngf=64, ngf_E=16, no_flip=1, num_threads=0, output_nc=3, phase='test', resize_or_crop='scaleWidth', serial_batches=False, size='large', suffix='.jpg', task='Feature2Face', test_dataset_names=['name'], tf_log=True, verbose=False)\n",
      "---------- Generator networks initialized -------------\n",
      "-------------------------------------------------------\n",
      "initialize network with normal\n",
      "model [Feature2FaceModel] was created\n",
      "loading the model from pretrained_models/LiveSpeechPortraits/data/May/checkpoints/Feature2Face.pkl\n",
      "---------- Networks initialized -------------\n",
      "[Network Feature2Face_G] Total number of parameters : 121.790 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = LiveSpeechPortraits(vid_res=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Computing APC features...\n",
      "2. Manifold projection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLE projection: 100%|██████████| 822/822 [00:00<00:00, 17135.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Audio2Mouth inference...\n",
      "4. Headpose inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating headpose: 100%|██████████| 396/396 [00:03<00:00, 113.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Post-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [00:00<00:00, 21470.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Image2Image translation & Saving results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image2Image translation inference: 100%|██████████| 50/50 [00:53<00:00,  1.08s/it]\n",
      "writing video: 100%|██████████| 396/396 [00:20<00:00, 18.91it/s]\n",
      "ffmpeg version 4.4.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.4.0 (GCC)\n",
      "  configuration: --prefix=/kuacc/users/mali18/.conda/envs/taming-default --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-vaapi --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-libvpx --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, avi, from 'sample_results/sample_data/audio/sample/tmp.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf58.49.100\n",
      "  Duration: 00:00:06.60, start: 0.000000, bitrate: 1917 kb/s\n",
      "  Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 1903 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'sample_results/sample_data/audio/sample/tmp.wav':\n",
      "  Duration: 00:00:06.86, bitrate: 512 kb/s\n",
      "  Stream #1:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "sample_results/sample_data/audio/sample/sample_data/audio/sample.avi: No such file or directory\n",
      "writing video: 100%|██████████| 396/396 [00:05<00:00, 71.99it/s]\n",
      "ffmpeg version 4.4.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.4.0 (GCC)\n",
      "  configuration: --prefix=/kuacc/users/mali18/.conda/envs/taming-default --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-vaapi --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-libvpx --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1636205340875/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, avi, from 'sample_results/sample_data/audio/sample/tmp.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf58.49.100\n",
      "  Duration: 00:00:06.60, start: 0.000000, bitrate: 3491 kb/s\n",
      "  Stream #0:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 3481 kb/s, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "Guessed Channel Layout for Input Stream #1.0 : mono\n",
      "Input #1, wav, from 'sample_results/sample_data/audio/sample/tmp.wav':\n",
      "  Duration: 00:00:06.86, bitrate: 512 kb/s\n",
      "  Stream #1:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 16000 Hz, mono, flt, 512 kb/s\n",
      "sample_results/sample_data/audio/sample/sample_data/audio/sample_feature_maps.avi: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish!\n",
      "CPU times: user 34.7 s, sys: 7.74 s, total: 42.5 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.generate_protrait('sample_data/audio/sample.wav', fps=30, batch_size=8, make_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (coolingo)",
   "language": "python",
   "name": "coolingo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
